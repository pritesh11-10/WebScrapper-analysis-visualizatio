# WebScrapper-analysis-visualization

Python libraries used for scrapper : Requests, Beautiful soup, pandas

Python libraries used for analysis : pandas, numpy

Python libraries used for visualization : plotly

What is Web Scrapper?

Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. Web scraping software may access the World Wide Web directly using the Hypertext Transfer Protocol, or through a web browser. While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying, in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later retrieval or analysis.

The Web Scraping process : 3 simple steps

1. First, we need to develop a scraper specifically to target and extract the data you want from the websites you want it from.

2. The data is retrieved in HTML format, after which it is carefully parsed to extricate the raw data you want from the noise surrounding it. Depending on the project, the data can be as simple as a name and address in some cases.

3. Ultimately, the data is stored in the format and to the exact specifications of the project. Some companies use third party applications or databases to view and manipulate the data to their choosing, while others prefer it in a simple, raw format - generally as CSV, TSV or JSON.

